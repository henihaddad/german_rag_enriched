{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['contexts', 'question', 'answer', 'positive_ctx_idx'],\n",
       "        num_rows: 3362\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets  \n",
    "dataset_name = \"DiscoResearch/germanrag\"  \n",
    "dataset = datasets.load_dataset(dataset_name) \n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/Mar/2024 03:48:09] INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8zy5gZl7vCmobeBkz02xaeWlGccjZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of Germany is Berlin.', role='assistant', function_call=None, tool_calls=None))], created=1709779688, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=7, prompt_tokens=24, total_tokens=31))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "#test client connectivity\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"What is the capital of Germany?\"}])\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-ada-002\"):\n",
    "    \"\"\"\n",
    "    Fetch embeddings for a list of texts using OpenAI's API.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for text_batch in np.array_split(texts, max(1, len(texts) // 20)):  # Splitting texts into manageable batches\n",
    "        response = client.embeddings.create(input=text_batch.tolist(), model=model)\n",
    "        embeddings += [r.embedding for r in response.data]\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def compute_similarity_scores(embeddings_1, embeddings_2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity scores between two sets of embeddings.\n",
    "    \"\"\"\n",
    "    # Normalize embeddings to unit length\n",
    "    embeddings_1 = normalize(embeddings_1)\n",
    "    embeddings_2 = normalize(embeddings_2)\n",
    "    \n",
    "    return np.dot(embeddings_1, embeddings_2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def generate_hash(*contexts):\n",
    "    \"\"\"Generate a hash for a combination of contexts.\"\"\"\n",
    "    concatenated_contexts = ''.join(sorted(contexts))  # Sort contexts to ensure order doesn't affect hash\n",
    "    return hashlib.md5(concatenated_contexts.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "def filter_candidate_contexts(question_embedding, candidate_contexts_df, pos_context_embedding, hard_negatives_embeddings, similarity_intervals):\n",
    "    \"\"\"\n",
    "    Filters candidate contexts based on similarity scores to the question, positive context, and hard negatives.\n",
    "\n",
    "    Parameters:\n",
    "    - question_embedding: The embedding of the current question.\n",
    "    - candidate_contexts_df: DataFrame of candidate contexts with their embeddings.\n",
    "    - pos_context_embedding: The embedding of the positive context for the current question.\n",
    "    - hard_negatives_embeddings: List of embeddings for hard negative contexts.\n",
    "    - similarity_intervals: A dict containing similarity intervals for question, positive, and hard negatives.\n",
    "\n",
    "    Returns:\n",
    "    - A filtered DataFrame of candidate contexts based on the provided similarity intervals.\n",
    "    \"\"\"\n",
    "    # Calculate similarity scores\n",
    "    candidate_contexts_df= candidate_contexts_df.copy()\n",
    "    similarity_to_question = compute_similarity_scores(question_embedding.reshape(1, -1), candidate_contexts_df['embeddings'].tolist())\n",
    "    similarity_to_question = list(chain.from_iterable(similarity_to_question))\n",
    "    \n",
    "    similarity_to_positive = compute_similarity_scores([pos_context_embedding], candidate_contexts_df['embeddings'].tolist())\n",
    "    similarity_to_positive = list(chain.from_iterable(similarity_to_positive))\n",
    "    \n",
    "    if hard_negatives_embeddings:\n",
    "        similarity_to_negatives = compute_similarity_scores(np.array(hard_negatives_embeddings), np.array(candidate_contexts_df['embeddings'].tolist()))\n",
    "        similarity_to_negatives = np.max(similarity_to_negatives, axis=0)\n",
    "        candidate_contexts_df['similarity_to_negatives'] = similarity_to_negatives\n",
    "    \n",
    "    # Assign similarity scores to DataFrame\n",
    "    candidate_contexts_df['similarity_to_question'] = similarity_to_question\n",
    "    candidate_contexts_df['similarity_to_positive'] = similarity_to_positive\n",
    "\n",
    "    # Filter based on similarity intervals\n",
    "    q_interval = similarity_intervals['question']\n",
    "    p_interval = similarity_intervals['positive']\n",
    "    filtered_df = candidate_contexts_df[(candidate_contexts_df['similarity_to_question'] >= q_interval[0]) & \n",
    "                                        (candidate_contexts_df['similarity_to_question'] <= q_interval[1]) &\n",
    "                                        (candidate_contexts_df['similarity_to_positive'] >= p_interval[0]) & \n",
    "                                        (candidate_contexts_df['similarity_to_positive'] <= p_interval[1])]\n",
    "    \n",
    "    if hard_negatives_embeddings:\n",
    "        n_interval = similarity_intervals['hard_negative']\n",
    "        filtered_df = filtered_df[(filtered_df['similarity_to_negatives'] >= n_interval[0]) & \n",
    "                                  (filtered_df['similarity_to_negatives'] <= n_interval[1])]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/Mar/2024 03:48:09] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:11] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:12] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:13] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:14] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:15] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:16] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:17] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:18] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:19] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:20] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:21] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:22] INFO - Loaded 250 contexts for 100 questions.\n",
      "[07/Mar/2024 03:48:22] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:23] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:24] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:25] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[07/Mar/2024 03:48:26] INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "[ 0.02220763 -0.00037119 -0.00995746 ...  0.01681731  0.01289042\n",
      " -0.01357336]\n",
      "[07/Mar/2024 03:48:26] INFO - Successfully added easy negatives for question 0.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 1.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 2.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 3.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 4.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 5.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 6.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 7.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 8.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 9.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 10.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 11.\n",
      "[07/Mar/2024 03:48:27] INFO - Successfully added easy negatives for question 12.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 13.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 14.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 15.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 16.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 17.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 18.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 19.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 20.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 21.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 22.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 23.\n",
      "[07/Mar/2024 03:48:28] INFO - Successfully added easy negatives for question 24.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 25.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 26.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 27.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 28.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 29.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 30.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 31.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 32.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 33.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 34.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 35.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 36.\n",
      "[07/Mar/2024 03:48:29] INFO - Successfully added easy negatives for question 37.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 38.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 39.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 40.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 41.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 42.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 43.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 44.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 45.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 46.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 47.\n",
      "[07/Mar/2024 03:48:30] INFO - Successfully added easy negatives for question 48.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 49.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 50.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 51.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 52.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 53.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 54.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 55.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 56.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 57.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 58.\n",
      "[07/Mar/2024 03:48:31] INFO - Successfully added easy negatives for question 59.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 60.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 61.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 62.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 63.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 64.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 65.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 66.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 67.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 68.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 69.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 70.\n",
      "[07/Mar/2024 03:48:32] INFO - Successfully added easy negatives for question 71.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 72.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 73.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 74.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 75.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 76.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 77.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 78.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 79.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 80.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 81.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 82.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 83.\n",
      "[07/Mar/2024 03:48:33] INFO - Successfully added easy negatives for question 84.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 85.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 86.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 87.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 88.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 89.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 90.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 91.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 92.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 93.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 94.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 95.\n",
      "[07/Mar/2024 03:48:34] INFO - Successfully added easy negatives for question 96.\n",
      "[07/Mar/2024 03:48:35] INFO - Successfully added easy negatives for question 97.\n",
      "[07/Mar/2024 03:48:35] INFO - Successfully added easy negatives for question 98.\n",
      "[07/Mar/2024 03:48:35] INFO - Successfully added easy negatives for question 99.\n",
      "first question Wie viele christlichen Menschen in Deutschland glauben an einen Gott?\n",
      "first easy negative ['Wasserwerfer\\n\\n== Einsatzprofil ==\\nLöschen einer brennenden Barrikade durch einen Wasserwerfer\\nWasserwerfer der französischen Polizei\\nWasserwerfer werden als Einsatzmittel zur Gefahrenabwehr vor allem bei Demonstrationen und Straßenschlachten eingesetzt, um größere Menschengruppen unter Kontrolle zu halten. Dies geschieht, um im Rahmen des unmittelbaren Zwangs Maßnahmen gewaltsam durchzusetzen. Wann dies geschehen darf, ist in Deutschland durch die Polizeidienstvorschrift PDV 122 eindeutig geregelt. Dies können auch Einsätze sein, deren Einsatzziel nicht mit personellen Mitteln allein oder nicht in der erforderlichen Zeit erbracht werden kann, wie das Räumen von Sitzblockaden. Weiterhin können Wasserwerfer auch in der Brandbekämpfung eingesetzt werden, etwa bei in Brand gesetzten Barrikaden oder aufgrund des meist vorhandenen Allradantriebs und ihrer Geländegängigkeit auch bei Waldbränden. In einigen Staaten verfügen diese Fahrzeuge über Räum- oder Absperrvorrichtungen.', \"IPod\\n\\n==== Product Red ====\\nAm 13.\\xa0Oktober 2006 wurde der ''iPod nano Product Red'' von U2-Frontmann Bono und der US-Talkmasterin Oprah Winfrey vorgestellt. Je verkauftem Gerät dieser Special Edition werden von Apple 10\\xa0$ an die HIV/AIDS-Hilfestiftung „Global Funds“ gespendet. Auch den am 12.\\xa0September 2006 vorgestellten iPod nano der zweiten Generation gibt es als ''Product-Red-''Edition, ebenso wie erstmals den iPod shuffle. Aktuell ist diese Farbe für den iPod nano (7. Generation), iPod touch (6. Generation) und den iPod shuffle (4. Generation) ausschließlich im Apple Online Store sowie im Apple Store verfügbar.\", \"IPod\\n\\n====  Zweite Generation ====\\nAm 12.\\xa0September 2006 wurde der iPod shuffle der zweiten Generation von Steve Jobs vorgestellt. Den iPod shuffle gibt es seit dem 5.\\xa0September 2007 mit veränderten Farbtönen, die denen des iPod nano der dritten Generation entsprechen. Erstmals hat auch das kleinste Modell der iPod-Reihe eine ''Product-Red-Serie''. Seit dem 19. Februar 2008 gab es den iPod shuffle neben dem Modell mit 1\\xa0GB auch in einer 2-GB-Version. Am 9. September 2008 wurden die lieferbaren Farben des Shuffle geändert. Mit zum Lieferumfang gehört eine kleine Akku-Ladestation, die über den Kopfhöreranschluss des iPod shuffle angeschlossen wird. Auf der Gegenseite befinden sich zwei kleine Schalter, die zum Ein- bzw. Ausschalten und zum Wechsel zwischen den Funktionen „Shuffle“ und „In-Reihenfolge-spielen“ genutzt werden. Durch einen integrierten stabilen Clip lässt sich der iPod shuffle fast überall befestigen. Im Gegensatz zum Vorgänger ist sein Äußeres aus eloxiertem Aluminium gefertigt. Das Modell ist mit den Abmessungen von 27,3\\xa0× 41,2\\xa0× 10,5\\xa0mm (etwa die Größe der ''Apple Radio Remote,'' aber etwas dicker) und einem Gewicht von 15\\xa0Gramm kleiner und leichter als der Vorgänger und galt laut Apple als der derzeit kleinste Audio-Player weltweit.\", \"IPod\\n\\n==== Sechste Generation (iPod classic) ====\\nDer nun ''iPod classic'' genannte iPod 6G wurde von Steve Jobs am 5.\\xa0September 2007 auf einer Sonderveranstaltung mit dem Namen ''The Beat Goes On'' in San Francisco vorgestellt. Er ist mit einer Speicherkapazität von 80 oder 160\\xa0GB in den Farben Silber und Space Grey erhältlich. Die Laufzeit des Akkus verlängerte sich im reinen Musikbetrieb auf 30\\xa0Stunden beim 80-GB-Modell, beziehungsweise 40\\xa0Stunden beim 160-GB-Modell. Die Schale besteht aus Metall und ist zu den Seiten hin leicht abgeflacht. Außerdem ist das dreidimensionale Blättern durch Albencover möglich, genannt Cover Flow. Im Hauptmenü ist die Anzeige nun geteilt und zeigt links die Menüpunkte und rechts verschiedene Einblendungen wie Musik, Video und Extras. Mit der Generation 6.1 wurde er mit 120\\xa0GB Speicherplatz angeboten und verfügt über die ''Genius''-Funktionalität, bei der Wiedergabelisten mit „gut zueinander passenden Titeln“ erstellt werden können (Apple-Aussage: ''Songs that go great together'').\\nDie Generation 6.2, die seit dem 9.\\xa0September 2009 erhältlich war, wurde ausschließlich mit 160\\xa0GB Speicherplatz angeboten. Der offizielle Verkauf des iPod Classic wurde am 9.\\xa0September 2014 eingestellt.\\n   IPod 1G.jpg|iPod (1.\\xa0Generation)\\n   IPod 2G.jpg|iPod (2.\\xa0Generation)\\n   3G ipod in dock.jpg|iPod (3.\\xa0Generation) im Dock\\n   IPodphoto2.jpg|iPod photo 60\\xa0GB\\n   Ipod 5th Generation white rotated.png|iPod (5.\\xa0Generation)\\n   IPod classic.png|iPod classic (6.\\xa0Generation)\", \"Swissness\\nSIGG-Flasche mit Schweizerkreuz\\nSchweizer Schokolade mit Schweizer Flagge (rechts)\\nDer Begriff Swissness (Marke Schweiz, in der Romandie auch ''suissitude'' genannt) ist ein zum Ende der 1990er Jahre in der Schweiz aufgekommener scheinanglizistischer Neologismus. Der Modebegriff postuliert die Dachmarkenstrategie, die Schweiz wirtschaftlich als trendige Marke zu positionieren. Die positiv konnotierten Attribute Fairness, Präzision, Zuverlässigkeit, politische Stabilität, Natürlichkeit und Sauberkeit sollen in einem Begriff zusammengefasst und als typisch schweizerisch insbesondere auch im Ausland vermarktet werden.\"]\n",
      "second question Wann werden Kleinspannungsglühlampen aufgrund ihrer Vorteile eingesetzt?\n",
      "second easy negative [\"IPod\\n\\n==== Product Red ====\\nAm 13.\\xa0Oktober 2006 wurde der ''iPod nano Product Red'' von U2-Frontmann Bono und der US-Talkmasterin Oprah Winfrey vorgestellt. Je verkauftem Gerät dieser Special Edition werden von Apple 10\\xa0$ an die HIV/AIDS-Hilfestiftung „Global Funds“ gespendet. Auch den am 12.\\xa0September 2006 vorgestellten iPod nano der zweiten Generation gibt es als ''Product-Red-''Edition, ebenso wie erstmals den iPod shuffle. Aktuell ist diese Farbe für den iPod nano (7. Generation), iPod touch (6. Generation) und den iPod shuffle (4. Generation) ausschließlich im Apple Online Store sowie im Apple Store verfügbar.\", \"IPod\\n\\n==== Sechste Generation (iPod classic) ====\\nDer nun ''iPod classic'' genannte iPod 6G wurde von Steve Jobs am 5.\\xa0September 2007 auf einer Sonderveranstaltung mit dem Namen ''The Beat Goes On'' in San Francisco vorgestellt. Er ist mit einer Speicherkapazität von 80 oder 160\\xa0GB in den Farben Silber und Space Grey erhältlich. Die Laufzeit des Akkus verlängerte sich im reinen Musikbetrieb auf 30\\xa0Stunden beim 80-GB-Modell, beziehungsweise 40\\xa0Stunden beim 160-GB-Modell. Die Schale besteht aus Metall und ist zu den Seiten hin leicht abgeflacht. Außerdem ist das dreidimensionale Blättern durch Albencover möglich, genannt Cover Flow. Im Hauptmenü ist die Anzeige nun geteilt und zeigt links die Menüpunkte und rechts verschiedene Einblendungen wie Musik, Video und Extras. Mit der Generation 6.1 wurde er mit 120\\xa0GB Speicherplatz angeboten und verfügt über die ''Genius''-Funktionalität, bei der Wiedergabelisten mit „gut zueinander passenden Titeln“ erstellt werden können (Apple-Aussage: ''Songs that go great together'').\\nDie Generation 6.2, die seit dem 9.\\xa0September 2009 erhältlich war, wurde ausschließlich mit 160\\xa0GB Speicherplatz angeboten. Der offizielle Verkauf des iPod Classic wurde am 9.\\xa0September 2014 eingestellt.\\n   IPod 1G.jpg|iPod (1.\\xa0Generation)\\n   IPod 2G.jpg|iPod (2.\\xa0Generation)\\n   3G ipod in dock.jpg|iPod (3.\\xa0Generation) im Dock\\n   IPodphoto2.jpg|iPod photo 60\\xa0GB\\n   Ipod 5th Generation white rotated.png|iPod (5.\\xa0Generation)\\n   IPod classic.png|iPod classic (6.\\xa0Generation)\", \"Swissness\\nSIGG-Flasche mit Schweizerkreuz\\nSchweizer Schokolade mit Schweizer Flagge (rechts)\\nDer Begriff Swissness (Marke Schweiz, in der Romandie auch ''suissitude'' genannt) ist ein zum Ende der 1990er Jahre in der Schweiz aufgekommener scheinanglizistischer Neologismus. Der Modebegriff postuliert die Dachmarkenstrategie, die Schweiz wirtschaftlich als trendige Marke zu positionieren. Die positiv konnotierten Attribute Fairness, Präzision, Zuverlässigkeit, politische Stabilität, Natürlichkeit und Sauberkeit sollen in einem Begriff zusammengefasst und als typisch schweizerisch insbesondere auch im Ausland vermarktet werden.\", \"Schweiz\\n\\n=== Küche ===\\nDie Schweizer Küche verbindet Einflüsse aus der deutschen, französischen und italienischen Küche. Sie ist regional sehr unterschiedlich, wobei die Sprachregionen eine Art Grobaufteilung bieten. Viele Gerichte haben die örtlichen Grenzen überschritten und sind in der ganzen Schweiz beliebt.\\nTypische Schweizer Gerichte sind Käsefondue, Raclette, Älplermagronen und Rösti. Diese hat auch den Röstigraben definiert. Östlich dieser Grenze gehört Rösti zu den populärsten Nationalgerichten, westlich davon nicht. Das heute weltweit bekannte Birchermüesli wurde um 1900 von einem Schweizer Arzt, Maximilian Bircher-Benner, in Zürich entwickelt. Die Honig-Mandel-Nougat-Schokolade Toblerone wird seit über 100 Jahren nur in Bern hergestellt und von dort aus in über 120 Länder verkauft. Der Cervelat ist die wohl beliebteste Wurst der Schweiz.\\nSehr beliebte Schweizer Produkte sind Schweizer Käse sowie Schweizer Schokolade. Zu lokalen Spezialitäten gehören etwa: Basler Läckerli, Vermicelles, Appenzeller Biber, Baiser, die Aargauer Rüeblitorte oder die Zuger Kirschtorte.\\nIn der Schweiz sehr beliebt ist das Süssgetränk Rivella. Das im Aargau produzierte Getränk konnte sich international allerdings bis jetzt nur in den Niederlanden durchsetzen. Auch die Ovomaltine ist eines der beliebtesten Schweizer Getränke. Im Gegensatz zu Rivella hat sich Ovomaltine weltweit verbreitet, mehrheitlich unter dem Namen ''Ovaltine''.\", 'Kultur_der_Schweiz\\nDie Kultur der Schweiz bezeichnet die Vielzahl von kulturellen Eigenheiten, die allein für die Schweiz typisch sind oder von ausserhalb betrachtet als typisch schweizerisch angesehen werden. Dazu gehören zum Beispiel die Schweizer Calvinistische Arbeitsethik, die nicht nur die Präzision der Schweizer Uhren und Maschinen förderte, sondern auch hohe Ansprüche an Käse oder Schokolade stellt.\\nDurch die verschiedenen Sprachen und Eigenheiten der Kantone unterscheiden sich die regionalen Kulturen teilweise stark voneinander. Sie lassen sich kulturwissenschaftlich\\xa0– mit Ausnahme der rätoromanischen Kultur\\xa0– den überstaatlichen deutschen, französischen und italienischen Kultur- und Sprachräumen zuordnen. \\nViele Künstler, Wissenschaftler, Ingenieure und Architekten, Hoteliers und Zuckerbäcker sowie Angehörige anderer Berufszweige, die in ihrer Not aus der Schweiz auswanderten wie zum Beispiel während der Hungersnot in den Jahren 1816/17 wurden bekannt. Andererseits zog die politische Neutralität der Schweiz auch Künstler und insbesondere Schriftsteller aus anderen Ländern an wie Georg Büchner, Hermann Hesse, Thomas Mann, Erich Maria Remarque, Paul Klee, Meret Oppenheim oder den Maler Ernst Ludwig Kirchner.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from itertools import chain\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_contexts_in_dataframe(dataset, model):\n",
    "    all_contexts = {'context': [], 'question_id':[], 'embeddings':[]}\n",
    "    for i, row in enumerate(dataset['train']):\n",
    "        for context in row['contexts']:\n",
    "            all_contexts['context'].append(context)\n",
    "            all_contexts['question_id'].append(i)\n",
    "\n",
    "    context_embeddings_column = get_embeddings(all_contexts['context'], model=model)\n",
    "    all_contexts['embeddings'] = context_embeddings_column.tolist()\n",
    "    return  pd.DataFrame(all_contexts)\n",
    "\n",
    "\n",
    "def add_easy_negatives(dataset, model=\"text-embedding-ada-002\", question_similarity_interval=(0.5, 0.75), hard_negative_similarity_interval=(0.5, 0.75), positive_similarity_interval=(0.5, 0.75), max_negative_examples=5):\n",
    "    \"\"\"\n",
    "    Add easy negative examples to a dataset by finding similar contexts for each question.\n",
    "    \"\"\"\n",
    "    all_contexts = load_contexts_in_dataframe(dataset,model)\n",
    "    logger.info(f\"Loaded {len(all_contexts)} contexts for {len(dataset['train'])} questions.\")\n",
    "    unique_combinations_set = set()\n",
    "    assert len(all_contexts) == len(all_contexts['context'])\n",
    "    assert all_contexts['question_id'].nunique() == len(dataset['train'])\n",
    "    \n",
    "    all_questions = dataset['train']['question']\n",
    "    question_embeddings = get_embeddings(all_questions, model=model)\n",
    "\n",
    "    easy_negatives=[]\n",
    "    for i, row in enumerate(dataset['train']):\n",
    "        condition = all_contexts['question_id'] == i\n",
    "        current_row_contexts = all_contexts[condition]\n",
    "        candidate_contexts = all_contexts[~condition]\n",
    "        assert len(all_contexts) == len(current_row_contexts) + len(candidate_contexts)\n",
    "\n",
    "        pos_idx=row['positive_ctx_idx']\n",
    "        similarity_intervals = {\n",
    "            'question': question_similarity_interval,\n",
    "            'positive': positive_similarity_interval,\n",
    "            'hard_negative': hard_negative_similarity_interval\n",
    "        }\n",
    "\n",
    "        pos_context_embedding = current_row_contexts.iloc[pos_idx]['embeddings']\n",
    "        hard_negatives_embeddings = [emb for i, emb in enumerate(current_row_contexts['embeddings']) if i != pos_idx]\n",
    "\n",
    "        candidate_contexts = filter_candidate_contexts(question_embeddings[i], candidate_contexts, pos_context_embedding, hard_negatives_embeddings, similarity_intervals)\n",
    "\n",
    "        # checking unicity of the combination\n",
    "        easy_negative_contexts=candidate_contexts['context'].tolist()[:max_negative_examples]\n",
    "        context_combinations_hash = generate_hash(*(easy_negative_contexts + row['contexts']))\n",
    "        while context_combinations_hash in unique_combinations_set and len(easy_negative_contexts) > 0:\n",
    "            easy_negative_contexts.pop()\n",
    "            context_combinations = easy_negative_contexts + row['contexts']\n",
    "            context_combinations_hash = generate_hash(*context_combinations)\n",
    "\n",
    "        easy_negatives.append(easy_negative_contexts)\n",
    "        unique_combinations_set.add(context_combinations_hash)\n",
    "        logger.info(f\"Successfully added easy negatives for question {i}.\")\n",
    "    dataset['train'] = dataset['train'].add_column(\"easy_negatives\", easy_negatives)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset10 = {'train': dataset['train'].select(range(100))}\n",
    "#we can use text-embedding-3-large for better results default set to text-embedding-ada-002\n",
    "new_dataset = add_easy_negatives(dataset10, question_similarity_interval=(0.2, 0.75), hard_negative_similarity_interval=(0.2, 0.8), positive_similarity_interval=(0.2, 0.75), max_negative_examples=5)['train']\n",
    "print(\"first question\", new_dataset['question'][0])\n",
    "print(\"first easy negative\", new_dataset['easy_negatives'][0])\n",
    "print(\"second question\", new_dataset['question'][1])\n",
    "print(\"second easy negative\", new_dataset['easy_negatives'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "primary_contexts = []\n",
    "lists_of_hard_negatives = []\n",
    "for i, row in enumerate(new_dataset):\n",
    "    primary_contexts.append(row['contexts'][row['positive_ctx_idx']])\n",
    "    lists_of_hard_negatives.append([row['contexts'][idx] for idx in range(len(row['contexts'])) if idx != row['positive_ctx_idx']])\n",
    "\n",
    "\n",
    "def prepare_dataset_entry(question, context, hard_negatives, easy_negatives, answer):\n",
    "    hard_negatives_formatted = '\\n- '.join(hard_negatives)\n",
    "    easy_negatives_formatted = '\\n- '.join(easy_negatives)\n",
    "    \n",
    "    entry = {\n",
    "        \"context\": f\"Primary Context: {context}\\n\\nSupplementary Contexts:\\nHard Negatives:\\n- {hard_negatives_formatted}\\nEasy Negatives:\\n- {easy_negatives_formatted}\",\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    \n",
    "    return entry\n",
    "\n",
    "def export_to_jsonl(entries, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for entry in entries:\n",
    "            file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "entries = []\n",
    "for q, c, h_negs, e_negs, a in zip(new_dataset['question'], primary_contexts, lists_of_hard_negatives, new_dataset['easy_negatives'], new_dataset['answer']):\n",
    "    entry = prepare_dataset_entry(q, c, h_negs, e_negs, a)\n",
    "    entries.append(entry)\n",
    "\n",
    "export_to_jsonl(entries, 'enriched_german_rag.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my approach to enhancing the germanrag dataset for ellamind, I've identified several areas where innovative techniques could significantly improve the dataset's utility for fine-tuning language models on German-language RAG applications. Here are my proposals:\n",
    "\n",
    "1. Dynamic Difficulty Scaling: Recognizing the importance of progressively challenging the model to ensure continuous learning and adaptation, I propose developing an algorithm that dynamically adjusts the difficulty level of questions and associated negatives based on the model's evolving performance. This system would not only ensure that the model is always being pushed to its learning edge but also prevent it from being overwhelmed by too complex questions too soon. Implementing such an algorithm involves categorizing our dataset into tiers of difficulty and incrementally exposing the model to more complex questions as its accuracy and confidence improve.\n",
    "\n",
    "2. Advanced Negative Selection: To further refine the model's ability to discern relevant from irrelevant or misleading information, I suggest an enhancement in our selection of negatives. This involves two key innovations:\n",
    "Algorithmic Refinement: Deploying advanced algorithms that go beyond semantic similarity to include logical and thematic divergence from the question's focus. This could leverage deep learning techniques to assess not just the textual similarity but the contextual relevance and potential for confusion, ensuring the negatives are sophisticated and challenging.\n",
    "Incorporation of Misinformation Negatives: In an era where misinformation is rampant, training the model to identify and disregard such content is crucial. I recommend including negatives that represent common misconceptions or misinformation within the dataset's domain. This strategy will not only improve the model's accuracy but also its applicability in real-world scenarios where discerning truth from falsehood is essential.\n",
    "\n",
    "3. Inclusion of Meta-Data: Understanding the context in which information is presented is pivotal for assessing its relevance and credibility. To this end, I propose augmenting the dataset with meta-data that describes the source, reliability, and date of each context. This addition will enable the model to consider not just the content of the information but also its origin and timeliness, factors that are often critical in determining the accuracy and relevance of an answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
